"""Metrics for use when analyzing the results of an EA run.

Basically, these classes allow us to think of an analysis as a
graph of nodes, where there are certain actions we can perform on
each type of data to produce new, processed types of data.

Each class is a thin wrapper around a DataFrame, and we assume that
the raw data comes in a format as generated by LEAP's
FitessStatesCSVProbe operator.
"""
import csv
import os
import shutil
import sys
import tempfile

import click
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import toolz

from leap_ec.probe import FitnessStatsCSVProbe


##############################
# Class BSFCurves
##############################
class BSFCurves():
    """Stores data from multiple EA runs (possibly consisting of many different
    algorithm configurations) and provides operations for analyzing them.
    
    One row per algorithm run."""
    def __init__(self, df, bsf_col='bsf', time_col='eval', job_col='job', groupby_cols=()):
        assert(df is not None)
        assert(groupby_cols in df.columns)
        assert(time_col in df.columns), f"Expected '{time_col}' column to be in {df.columns}."
        assert(bsf_col in df.columns), f"Expected '{bsf_col}' column to be in {df.columns}."
        self.df = df
        self.bsf_col = bsf_col
        self.time_col = time_col
        self.job_col = job_col
        self.groupby_cols = groupby_cols

    def average_bsf_curves(self, groupby_cols):
        """Average over different runs of each configuration."""
        return AvgBSFCurves.from_bsf_curves(self, groupby_cols)

    def scalar_metrics(self):
        """Compute scalar metrics summarizing each run."""
        return ScalarMetricsByRun.from_bsf_curves(self)

    def plot(self, title: str, xlabel: str = None, ylabel: str = None):
        """Plot all of the BSF curves in a single image."""
        plt.figure(figsize=(8,6))
        self.df.groupby(self.groupby_cols).plot(x=self.time_col, y=self.bsf_col, ax=plt.gca(), legend=False)
        if xlabel:
            plt.xlabel(xlabel)
        if ylabel:
            plt.ylabel(ylabel)
        plt.title(title)
        plt.show()


##############################
# Class AvgBSFCurves
##############################
class AvgBSFCurves():
    """Stores average performance curves computed from one or more algorithm
    configuration and provides operations for analyzing them.
    
    One row per algorithm configuration."""
    def __init__(self, df, time_col='eval', bsf_mean_col='bsf_mean', bsf_std_col='bsf_std', groupby_cols=()):
        assert(df is not None)
        self.df = df
        assert(time_col in self.df.columns), f"Expected '{time_col}' column to be in {df.columns}."
        assert(bsf_mean_col in self.df.columns), f"Expected '{bsf_mean_col}' column to be in {df.columns}."
        self.time_col = time_col
        self.bsf_mean_col = bsf_mean_col
        self.bsf_std_col = bsf_std_col
        self.groupby_cols = groupby_cols

    @staticmethod
    def from_bsf_curves(bsf_curves, groupby_cols):
        """Aggregate bsf curves for each algorithm configuration into average bsf-fitness curves."""
        assert(bsf_curves is not None)
        assert(groupby_cols is not None)
        df, bsf_col, time_col = bsf_curves.df, bsf_curves.bsf_col, bsf_curves.time_col

        group = [time_col] + groupby_cols
        avg_df = df[group + [bsf_col]].groupby(group).agg(['mean', 'std'])
        avg_df.columns = ['_'.join(col).strip() for col in avg_df.columns.values]
        avg_df.reset_index(inplace=True)
        return AvgBSFCurves(avg_df, time_col, f"{bsf_col}_mean", f"{bsf_col}_std")

    def plot(self, title, error_bars: bool, legend_column, ylim, xlabel: str = None, ylabel: str = None):
        """Plot the mean BSF curves in a single image."""
        plt.figure(figsize=(8,6))
        for name, group_df in self.df.groupby(self.groupby_cols, as_index=False):
            label = group_df[legend_column].iloc[0] if legend_column else name
            if error_bars:
                assert(self.bsf_std_col in self.df.columns), f"Expected '{self.bsf_std_col}' column to be in {df.columns}."
                group_df.plot(x=self.time_col, y=self.bsf_mean_col, yerr=self.bsf_std_col, capsize=4, fmt='o-', ax=plt.gca(), grid='on', ms=10, label=label)
            else:
                group_df.plot(x=self.time_col, y=self.bsf_mean_col, style='o-', ax=plt.gca(), grid='on', label=label)

        if not legend_column:
            plt.gca().get_legend().remove()
            
        if ylim:
            plt.ylim(*ylim)

        if xlabel:
            plt.xlabel(xlabel)
        if ylabel:
            plt.ylabel(ylabel)
        plt.title(title)
        plt.show()


##############################
# Function best()
##############################
@toolz.curry
def best(df, bsf_col):
    """Compute the best (highest) fitness value found across a group's 'bsf' attribute."""
    return pd.Series({'best': df[bsf_col].max()})


##############################
# Function auc()
##############################
@toolz.curry
def auc(df, bsf_col, time_col):
    """A fast area-under-BSF-curve function."""
    df = df[[time_col, bsf_col]].sort_values(time_col)
    df['previous_time'] = [df[time_col].min()] + df[time_col][0:len(df[time_col]) - 1].to_list()
    df['xdiff'] = df[time_col] - df.previous_time
    auc = sum(df.xdiff * df.bsf)
    return pd.Series({'auc': auc})


##############################
# Class ScalarMetricsByRun
##############################
class ScalarMetricsByRun():
    """Stores scalar performance metrics summarizing the result of individual runs
    for one or more algorithm configurations.
    
    One row per algorithm run."""
    def __init__(self, df, metric_cols, groupby_cols):
        assert(df is not None)
        assert(metric_cols is not None)
        self.df = df
        self.metric_cols = metric_cols
        self.groupby_cols = groupby_cols

    @staticmethod
    def from_bsf_curves(bsf_curves, metrics=(best('bsf'), auc('bsf', 'eval'))):
        """Aggregate the bsf curves for each algorithm into scalar metrics including the 
        area-under-curve."""
        assert(bsf_curves is not None)
        assert(metrics is not None)
        df, groupby_cols = bsf_curves.df, bsf_curves.groupby_cols
        metric_names = [ f.__name__ for f in metrics ]
        assert(all([ x in df.columns for x in metric_names ])), f"One or more of the metrics {metric_names} was missing in the dataframe's columns {df.columns}"

        df_perf = df[groupby_cols + metric_names].groupby(groupby_cols).apply(metrics)
        # df_perf = df[group + ['eval', 'bsf']].groupby(group).apply(best)
        # df_auc = df[group + ['eval', 'bsf']].groupby(group).apply(auc)
        # df_perf['auc'] = df_auc.auc
        df_perf.reset_index(inplace=True)
        return ScalarMetricsByRun(df_perf, metric_cols=metric_names, groupby_cols=groupby_cols)

    def average(self, groupby_cols):
        """Aggregate the separate runs of each algorithm configuration into a single
        row of scalar performance metrics for all runs of each configuration."""
        return AvgScalarMetrics.from_scalar_metrics_by_run(self.df, groupby_cols)


##############################
# Class AvgScalarMetrics
##############################
class AvgScalarMetrics():
    """Stores scalar performance metrics averaged over each algorithm configuratoin.
    
    One row per algorithm configuration."""
    def __init__(self, df, groupby_cols, metric_cols):
        assert(df is not None)
        self.df = df
        self.groupby_cols = groupby_cols
        self.metric_cols = metric_cols

    @staticmethod
    def from_scalar_metrics_by_run(scalar_metrics_by_run, groupby_cols):
        df = scalar_metrics_by_run.df
        metric_cols = scalar_metrics_by_run.metric_cols
        assert(all([ x in df.columns for x in metric_cols ]))

        # Just grouping by note columns, since we want to average over jobs, and there is just one row
        # per job-configuration pair.
        avg_df = df[groupby_cols + metric_cols].groupby(groupby_cols).agg(['mean', 'std'])
        avg_df.columns = ['_'.join(col).strip() for col in avg_df.columns.values]
        avg_df.reset_index(inplace=True)
        return AvgScalarMetrics(avg_df, groupby_cols, avg_df.columns)


    def plot(self, independent_vars: list, metric: str, line=True):
        assert(independent_vars is not None)
        assert(metric in self.metric_cols), f"Unknown metric {metric}.  Allows values are {self.metric_cols}."

        for v in independent_vars:
            cmap = sns.color_palette("coolwarm", as_cmap=True)
            plt.figure()
            x, y = np.array(self.df[v]), np.array(self.df[metric])
            plt.scatter(self.df[v], self.df[metric], c=self.df[metric], cmap=cmap)

            # Linear fit
            if line:
                m,b = np.polyfit(x, y, 1) 
                end_points = np.array([min(x), max(x)])
                plt.plot(end_points, m*end_points+b, '--k')

            plt.title(f"{v}")
            plt.show(block=False)


##############################
# CLI groups
##############################
@click.group()
def cli():
    """Experiments in evolving controllers for simple 2-D robots."""
    pass

@cli.group()
def analyze():
    """Analysis commands."""
    pass


@cli.group()
def plot():
    """Plotting commands."""
    pass


##############################
# Command analyze
##############################
@analyze.command()
@click.argument('files', nargs=-1)
@click.option('--time-col', default='step', type=str, help="Name of column that represent time (ex. generation, step, eval).")
def fitness(files, time_col):
    """
    Analyze a set of bsf-curve files by computing various metrics and averages.

    Outputs four new files in the current directory.
    """

    combined = './fitnesses_combined.csv'

    # Combine files into one big CSV
    with open(combined, 'w') as f:
        cat_csv_files(files, f)
    
    # Add an eval column, computed from pop_size, etc.
    # with tempfile.NamedTemporaryFile() as f:
    #     #add_eval_column(combined, f)
    #     f.flush()
    #     shutil.copy(f.name, combined)


    # Load as a DataFrame
    df = pd.read_csv(combined, skipinitialspace=True)

    # Wrap it in our analysis engine
    runs = BSFCurves(df, time_col=time_col)
    
    # Write out average BSF curves
    avg_bsf_runs = runs.average_bsf_curves()
    avg_bsf_runs.df.to_csv('./avg_bsf_curves.csv', index=False)

    # Write out area-under-curve
    # auc_runs = runs.scalar_metrics()
    # auc_runs.df.to_csv('./auc_by_run.csv', index=False)

    # # Write out average area-under-curve
    # auc_configs = auc_runs.average()
    # auc_configs.df.to_csv('./auc_by_config.csv', index=False)


##############################
# Command plot bsf
##############################
@plot.command()
@click.argument('fitness-file')
@click.option('--title', type=str, default='Best-so-Far Fitness')
@click.option('--time-col', default='step', type=str, help="Name of column that represent time (ex. generation, step, eval).")
def bsf(fitness_file, title, time_col):
    """Plot a single best-of-generation fitness curve from a CSV file."""
    assert(os.path.exists(fitness_file))
    df = pd.read_csv(fitness_file, skipinitialspace=True)
    curves = BSFCurves(df, time_col=time_col)
    curves.plot(title)


##############################
# Command plot avg-bsf
##############################
@plot.command('avg-bsf')
@click.argument('average-bsf-file')
@click.option('--title', type=str, default='Average Best-so-Far Fitness')
@click.option('--error/--no-error', type=bool, default=True)
@click.option('--legend-col', type=str, default=None)
@click.option('--ylim', type=(float, float), default=(None, None))
@click.option('--time-col', default='step', type=str, help="Name of column that represent time (ex. generation, step, eval).")
def avg_bsf(average_bsf_file, title, error, legend_col, ylim, time_col):
    """Plot average fitness curves from an average-fitness CSV file."""
    assert(os.path.exists(average_bsf_file))
    df = pd.read_csv(average_bsf_file, skipinitialspace=True)
    curves = AvgBSFCurves(df, time_col=time_col)
    curves.plot(title, error, legend_col, ylim)


##############################
# Function cat_csvs()
##############################
def cat_csv_files(files: list, stream=sys.stdout):
    """Combine a bunch of CSVs with the same columns into one CSV with a single header.
    
    The result is written to the given stream."""
    header = None
    writer = csv.writer(stream)

    for fname in files:
        with open(fname, 'r') as f:
            reader = csv.reader(f)

            if header is None:
                header = next(reader)
                writer.writerow(header)
            else:
                this_header = next(reader)
                if this_header != header:
                    raise ValueError(f"Inconsistent headers.  First file was:\n{header}\n\nbut found a file with\n{this_header}.")

            for row in reader:
                writer.writerow(row)


##############################
# Entry point
##############################
if __name__ == '__main__':
    cli()